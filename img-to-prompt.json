{"last_node_id": 10, "last_link_id": 7, "nodes": [{"id": 4, "type": "LoadImage", "pos": {"0": 452.0546875, "1": 188.640625, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 315, "1": 314}, "flags": {}, "order": 0, "mode": 0, "inputs": [], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [1], "slot_index": 0, "shape": 3}, {"name": "MASK", "type": "MASK", "links": null, "shape": 3}], "properties": {"Node name for S&R": "LoadImage"}, "widgets_values": ["ComfyUI_00022_.png", "image"]}, {"id": 3, "type": "OllamaVision", "pos": {"0": 800, "1": 190, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 400, "1": 200}, "flags": {}, "order": 2, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 1}], "outputs": [{"name": "description", "type": "STRING", "links": [2], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "OllamaVision"}, "widgets_values": ["describe the image", "enable", "http://127.0.0.1:11434", "llava:latest", 5]}, {"id": 5, "type": "ShowText|pysssss", "pos": {"0": 1270, "1": 150, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 491.26171875, "1": 228.4453125}, "flags": {}, "order": 3, "mode": 0, "inputs": [{"name": "text", "type": "STRING", "link": 2, "widget": {"name": "text"}}], "outputs": [{"name": "STRING", "type": "STRING", "links": [3], "shape": 6}], "properties": {"Node name for S&R": "ShowText|pysssss"}, "widgets_values": ["", " The image is a portrait of an individual, likely a woman, with fair skin. She has a gentle expression and her gaze is directed slightly to the side. Her hair is neatly pulled back and she is wearing what appears to be light makeup, possibly including lipstick and eyeliner.\n\nThe woman has an East Asian appearance, with prominent features such as well-defined eyebrows, full lips, and a straight nose. She is adorned with small gold jewelry in her ears and is wearing delicate white lace earrings. Her facial expression is serene and she seems to be posing for the photograph.\n\nShe has light brown hair, which falls just above her shoulders. The background of the photo is blurred but suggests an indoor setting, possibly a room with soft lighting. There are no visible texts or distinctive brands in the image. The focus is solely on the individual and her expression. "]}, {"id": 7, "type": "Text Concatenate", "pos": {"0": 1840, "1": 180, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 315, "1": 178}, "flags": {}, "order": 4, "mode": 0, "inputs": [{"name": "text_a", "type": "STRING", "link": 4, "widget": {"name": "text_a"}}, {"name": "text_b", "type": "STRING", "link": 3, "widget": {"name": "text_b"}}, {"name": "text_c", "type": "STRING", "link": null, "widget": {"name": "text_c"}}, {"name": "text_d", "type": "STRING", "link": null, "widget": {"name": "text_d"}}], "outputs": [{"name": "STRING", "type": "STRING", "links": [5], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "Text Concatenate"}, "widgets_values": ["", "true", "Convert the following text into a suitable prompt for text2img (stable diffusion). Do not output anything other than the prompt:", "", "", ""]}, {"id": 8, "type": "PrimitiveNode", "pos": {"0": 1630, "1": 40, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 210, "1": 58}, "flags": {}, "order": 1, "mode": 0, "inputs": [], "outputs": [{"name": "STRING", "type": "STRING", "links": [4], "widget": {"name": "text_a"}}], "properties": {"Run widget replace on values": false}, "widgets_values": ["Convert the following text into a suitable prompt for text2img (stable diffusion). Do not output anything other than the prompt:"]}, {"id": 9, "type": "ShowText|pysssss", "pos": {"0": 2220, "1": 190, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 386.15625, "1": 252.4296875}, "flags": {}, "order": 5, "mode": 0, "inputs": [{"name": "text", "type": "STRING", "link": 5, "widget": {"name": "text"}}], "outputs": [{"name": "STRING", "type": "STRING", "links": [6], "slot_index": 0, "shape": 6}], "properties": {"Node name for S&R": "ShowText|pysssss"}, "widgets_values": ["", "Convert the following text into a suitable prompt for text2img (stable diffusion). Do not output anything other than the prompt:The image is a portrait of an individual, likely a woman, with fair skin. She has a gentle expression and her gaze is directed slightly to the side. Her hair is neatly pulled back and she is wearing what appears to be light makeup, possibly including lipstick and eyeliner.\n\nThe woman has an East Asian appearance, with prominent features such as well-defined eyebrows, full lips, and a straight nose. She is adorned with small gold jewelry in her ears and is wearing delicate white lace earrings. Her facial expression is serene and she seems to be posing for the photograph.\n\nShe has light brown hair, which falls just above her shoulders. The background of the photo is blurred but suggests an indoor setting, possibly a room with soft lighting. There are no visible texts or distinctive brands in the image. The focus is solely on the individual and her expression."]}, {"id": 10, "type": "ShowText|pysssss", "pos": {"0": 3105, "1": 199, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 394.99383544921875, "1": 353.0799865722656}, "flags": {}, "order": 7, "mode": 0, "inputs": [{"name": "text", "type": "STRING", "link": 7, "widget": {"name": "text"}}], "outputs": [{"name": "STRING", "type": "STRING", "links": null, "shape": 6}], "properties": {"Node name for S&R": "ShowText|pysssss"}, "widgets_values": ["", "A portrait of a serene East Asian woman with fair skin, light brown hair just above her shoulders, and gentle expression, gazing slightly to the side. She wears neat pulled-back hair, subtle light makeup including lipstick and eyeliner, and delicate gold earrings adorned with white lace, set against a blurred indoor background with soft lighting."]}, {"id": 6, "type": "OllamaGenerate", "pos": {"0": 2640, "1": 200, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 400, "1": 200}, "flags": {}, "order": 6, "mode": 0, "inputs": [{"name": "prompt", "type": "STRING", "link": 6, "widget": {"name": "prompt"}}], "outputs": [{"name": "response", "type": "STRING", "links": [7], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "OllamaGenerate"}, "widgets_values": ["What is Art?", "enable", "http://127.0.0.1:11434", "llama3.1:8b", 5]}], "links": [[1, 4, 0, 3, 0, "IMAGE"], [2, 3, 0, 5, 0, "STRING"], [3, 5, 0, 7, 1, "STRING"], [4, 8, 0, 7, 0, "STRING"], [5, 7, 0, 9, 0, "STRING"], [6, 9, 0, 6, 0, "STRING"], [7, 6, 0, 10, 0, "STRING"]], "groups": [], "config": {}, "extra": {"ds": {"scale": 0.513158118230707, "offset": [-596.9049634197761, 599.5314748720721]}, "groupNodes": {"yuichkun::sdxl-turbo": {"author": "Yuichi Yogo", "category": "", "config": {"1": {"input": {"ckpt_name": {"visible": false}}}, "6": {"input": {"add_noise": {"visible": false}}, "output": {"1": {"visible": false}}}}, "datetime": 1725553184575, "external": [[7, 0, "IMAGE"]], "links": [[1, 0, 3, 0, 4, "MODEL"], [1, 1, 4, 0, 4, "CLIP"], [1, 1, 5, 0, 4, "CLIP"], [1, 0, 6, 0, 4, "MODEL"], [5, 0, 6, 1, 7, "CONDITIONING"], [4, 0, 6, 2, 8, "CONDITIONING"], [0, 0, 6, 3, 3, "SAMPLER"], [3, 0, 6, 4, 6, "SIGMAS"], [2, 0, 6, 5, 5, "LATENT"], [6, 0, 7, 0, 9, "LATENT"], [1, 2, 7, 1, 4, "VAE"]], "nodes": [{"flags": {}, "id": -1, "index": 0, "inputs": [], "mode": 0, "order": 0, "outputs": [{"links": [], "name": "SAMPLER", "shape": 3, "type": "SAMPLER"}], "pos": {"0": 1031, "1": 413, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "KSamplerSelect"}, "size": {"0": 315, "1": 58}, "type": "KSamplerSelect", "widgets_values": ["euler"]}, {"flags": {}, "id": -1, "index": 1, "inputs": [], "mode": 0, "order": 1, "outputs": [{"links": [], "name": "MODEL", "shape": 3, "slot_index": 0, "type": "MODEL"}, {"links": [], "name": "CLIP", "shape": 3, "slot_index": 1, "type": "CLIP"}, {"links": [], "name": "VAE", "shape": 3, "slot_index": 2, "type": "VAE"}], "pos": {"0": 538, "1": 262, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "CheckpointLoaderSimple"}, "size": {"0": 343.69647216796875, "1": 98}, "type": "CheckpointLoaderSimple", "widgets_values": ["SDXL-TURBO/sd_xl_turbo_1.0_fp16.safetensors"]}, {"flags": {}, "id": -1, "index": 2, "inputs": [], "mode": 0, "order": 2, "outputs": [{"links": [], "name": "LATENT", "slot_index": 0, "type": "LATENT"}], "pos": {"0": 992, "1": 916, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "EmptyLatentImage"}, "size": {"0": 315, "1": 106}, "type": "EmptyLatentImage", "widgets_values": [512, 512, 1]}, {"flags": {}, "id": -1, "index": 3, "inputs": [{"link": null, "name": "model", "slot_index": 0, "type": "MODEL"}], "mode": 0, "order": 3, "outputs": [{"links": [], "name": "SIGMAS", "shape": 3, "slot_index": 0, "type": "SIGMAS"}], "pos": {"0": 1151, "1": 106, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "SDTurboScheduler"}, "size": {"0": 315, "1": 82}, "type": "SDTurboScheduler", "widgets_values": [1, 1]}, {"flags": {}, "id": -1, "index": 4, "inputs": [{"link": null, "name": "clip", "type": "CLIP"}], "mode": 0, "order": 4, "outputs": [{"links": [], "name": "CONDITIONING", "slot_index": 0, "type": "CONDITIONING"}], "pos": {"0": 526, "1": 584, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "CLIPTextEncode"}, "size": {"0": 425.27801513671875, "1": 180.6060791015625}, "title": "Negative Prompt", "type": "CLIPTextEncode", "widgets_values": [""]}, {"flags": {}, "id": -1, "index": 5, "inputs": [{"link": null, "name": "clip", "slot_index": 0, "type": "CLIP"}, {"link": null, "name": "text", "type": "STRING", "widget": {"name": "text"}}], "mode": 0, "order": 5, "outputs": [{"links": [], "name": "CONDITIONING", "slot_index": 0, "type": "CONDITIONING"}], "pos": {"0": 397, "1": 529, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "CLIPTextEncode"}, "size": {"0": 422.84503173828125, "1": 164.31304931640625}, "title": "Positive Prompt", "type": "CLIPTextEncode", "widgets_values": [""]}, {"flags": {}, "id": -1, "index": 6, "inputs": [{"link": null, "name": "model", "slot_index": 0, "type": "MODEL"}, {"link": null, "name": "positive", "slot_index": 1, "type": "CONDITIONING"}, {"link": null, "name": "negative", "type": "CONDITIONING"}, {"link": null, "name": "sampler", "slot_index": 3, "type": "SAMPLER"}, {"link": null, "name": "sigmas", "slot_index": 4, "type": "SIGMAS"}, {"link": null, "name": "latent_image", "slot_index": 5, "type": "LATENT"}], "mode": 0, "order": 6, "outputs": [{"links": [], "name": "output", "shape": 3, "slot_index": 0, "type": "LATENT"}, {"links": null, "name": "denoised_output", "shape": 3, "type": "LATENT"}], "pos": {"0": 1379, "1": 491, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "SamplerCustom"}, "size": {"0": 355.20001220703125, "1": 230}, "type": "SamplerCustom", "widgets_values": [true, 0, "randomize", 8]}, {"flags": {}, "id": -1, "index": 7, "inputs": [{"link": null, "name": "samples", "type": "LATENT"}, {"link": null, "name": "vae", "slot_index": 1, "type": "VAE"}], "mode": 0, "order": 7, "outputs": [{"links": [], "name": "IMAGE", "slot_index": 0, "type": "IMAGE"}], "pos": {"0": 1599, "1": 354, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "VAEDecode"}, "size": {"0": 210, "1": 46}, "type": "VAEDecode"}], "packname": "", "version": "0.0"}, "yuichkun::stable-audio": {"author": "Yuichi Yogo", "category": "audio", "config": {"0": {"input": {"ckpt_name": {"visible": false}}}, "1": {"input": {"clip_name": {"visible": false}, "type": {"visible": false}}}, "4": {"input": {"text": {"name": "Negative Prompt"}}}}, "datetime": 1725554376722, "external": [[6, 0, "AUDIO"]], "links": [[1, 0, 3, 0, 10, "CLIP"], [1, 0, 4, 0, 10, "CLIP"], [0, 0, 5, 0, 4, "MODEL"], [3, 0, 5, 1, 6, "CONDITIONING"], [4, 0, 5, 2, 7, "CONDITIONING"], [2, 0, 5, 3, 11, "LATENT"], [5, 0, 6, 0, 3, "LATENT"], [0, 2, 6, 1, 4, "VAE"]], "nodes": [{"flags": {}, "id": -1, "index": 0, "inputs": [], "mode": 0, "order": 0, "outputs": [{"links": [], "name": "MODEL", "slot_index": 0, "type": "MODEL"}, {"links": [], "name": "CLIP", "slot_index": 1, "type": "CLIP"}, {"links": [], "name": "VAE", "slot_index": 2, "type": "VAE"}], "pos": {"0": 713, "1": 234, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "CheckpointLoaderSimple"}, "size": {"0": 336, "1": 98}, "type": "CheckpointLoaderSimple", "widgets_values": ["stable_audio_open_1.0.safetensors"]}, {"flags": {}, "id": -1, "index": 1, "inputs": [], "mode": 0, "order": 1, "outputs": [{"links": [], "name": "CLIP", "shape": 3, "slot_index": 0, "type": "CLIP"}], "pos": {"0": 713, "1": 90, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "CLIPLoader"}, "size": {"0": 335.6534118652344, "1": 82}, "type": "CLIPLoader", "widgets_values": ["t5_base.safetensors", "stable_audio"]}, {"flags": {}, "id": -1, "index": 2, "inputs": [], "mode": 0, "order": 2, "outputs": [{"links": [], "name": "LATENT", "shape": 3, "type": "LATENT"}], "pos": {"0": 1289, "1": 474, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "EmptyLatentAudio"}, "size": {"0": 240, "1": 58}, "type": "EmptyLatentAudio", "widgets_values": [47.6]}, {"bgcolor": "#353", "color": "#232", "flags": {}, "id": -1, "index": 3, "inputs": [{"link": null, "name": "clip", "type": "CLIP"}, {"link": null, "name": "text", "type": "STRING", "widget": {"name": "text"}}], "mode": 0, "order": 3, "outputs": [{"links": [], "name": "CONDITIONING", "slot_index": 0, "type": "CONDITIONING"}], "pos": {"0": 1097, "1": 90, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "CLIPTextEncode"}, "size": {"0": 432, "1": 144}, "type": "CLIPTextEncode", "widgets_values": ["heaven church electronic dance music"]}, {"bgcolor": "#533", "color": "#322", "flags": {}, "id": -1, "index": 4, "inputs": [{"link": null, "name": "clip", "type": "CLIP"}], "mode": 0, "order": 4, "outputs": [{"links": [], "name": "CONDITIONING", "slot_index": 0, "type": "CONDITIONING"}], "pos": {"0": 1097, "1": 282, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "CLIPTextEncode"}, "size": {"0": 432, "1": 144}, "type": "CLIPTextEncode", "widgets_values": [""]}, {"flags": {}, "id": -1, "index": 5, "inputs": [{"link": null, "name": "model", "type": "MODEL"}, {"link": null, "name": "positive", "type": "CONDITIONING"}, {"link": null, "name": "negative", "type": "CONDITIONING"}, {"link": null, "name": "latent_image", "slot_index": 3, "type": "LATENT"}], "mode": 0, "order": 5, "outputs": [{"links": [], "name": "LATENT", "slot_index": 0, "type": "LATENT"}], "pos": {"0": 1577, "1": 90, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "KSampler"}, "size": {"0": 315, "1": 262}, "type": "KSampler", "widgets_values": [1103134701216948, "randomize", 50, 4.98, "dpmpp_3m_sde_gpu", "exponential", 1]}, {"flags": {}, "id": -1, "index": 6, "inputs": [{"link": null, "name": "samples", "type": "LATENT"}, {"link": null, "name": "vae", "slot_index": 1, "type": "VAE"}], "mode": 0, "order": 6, "outputs": [{"links": [], "name": "AUDIO", "shape": 3, "slot_index": 0, "type": "AUDIO"}], "pos": {"0": 1913, "1": 90, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "VAEDecodeAudio"}, "size": {"0": 210, "1": 46}, "type": "VAEDecodeAudio"}], "packname": "", "version": "0.0"}}}, "version": 0.4}