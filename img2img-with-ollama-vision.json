{"last_node_id": 34, "last_link_id": 45, "nodes": [{"id": 13, "type": "ShowText|pysssss", "pos": {"0": 865, "1": 218}, "size": {"0": 491.26171875, "1": 448.4453125}, "flags": {}, "order": 8, "mode": 0, "inputs": [{"name": "text", "type": "STRING", "link": 14, "widget": {"name": "text"}}], "outputs": [{"name": "STRING", "type": "STRING", "links": [17], "shape": 6}], "properties": {"Node name for S&R": "ShowText|pysssss"}, "widgets_values": ["", " The image is a portrait of a young woman posing outdoors. She has long, straight hair and is wearing a white kimono with light-colored, intricate detailing on the right side of her clothing. The woman appears to be standing in a park or garden setting, as there are trees and a fence visible behind her. Her pose suggests a relaxed and casual demeanor, with one hand gently touching the side of her face while the other is slightly extended downwards. She is looking directly at the camera with a neutral expression on her face. The photo captures natural light, which casts soft shadows on the ground and enhances the greenery in the background. "]}, {"id": 15, "type": "Text Concatenate", "pos": {"0": 1406.26171875, "1": 80}, "size": {"0": 315, "1": 178}, "flags": {}, "order": 9, "mode": 0, "inputs": [{"name": "text_a", "type": "STRING", "link": 16, "widget": {"name": "text_a"}}, {"name": "text_b", "type": "STRING", "link": 17, "widget": {"name": "text_b"}}, {"name": "text_c", "type": "STRING", "link": null, "widget": {"name": "text_c"}}, {"name": "text_d", "type": "STRING", "link": null, "widget": {"name": "text_d"}}], "outputs": [{"name": "STRING", "type": "STRING", "links": [18], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "Text Concatenate"}, "widgets_values": ["", "true", "Convert the following text into a suitable prompt for text2img (stable diffusion). Do not output anything other than the prompt:", "", "", ""]}, {"id": 14, "type": "OllamaGenerate", "pos": {"0": 2207.41796875, "1": 80}, "size": {"0": 400, "1": 200}, "flags": {}, "order": 11, "mode": 0, "inputs": [{"name": "prompt", "type": "STRING", "link": 15, "widget": {"name": "prompt"}}], "outputs": [{"name": "response", "type": "STRING", "links": [20], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "OllamaGenerate"}, "widgets_values": ["What is Art?", "enable", "http://127.0.0.1:11434", "llama3.1:8b", 5]}, {"id": 12, "type": "OllamaVision", "pos": {"0": 415, "1": 80}, "size": {"0": 400, "1": 200}, "flags": {}, "order": 5, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 21}], "outputs": [{"name": "description", "type": "STRING", "links": [14], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "OllamaVision"}, "widgets_values": ["describe the image", "enable", "http://127.0.0.1:11434", "llava:latest", 5]}, {"id": 16, "type": "PrimitiveNode", "pos": {"0": 1146.26171875, "1": 80}, "size": {"0": 210, "1": 58}, "flags": {}, "order": 0, "mode": 0, "inputs": [], "outputs": [{"name": "STRING", "type": "STRING", "links": [16], "widget": {"name": "text_a"}}], "properties": {"Run widget replace on values": false}, "widgets_values": ["Convert the following text into a suitable prompt for text2img (stable diffusion). Do not output anything other than the prompt:"]}, {"id": 17, "type": "ShowText|pysssss", "pos": {"0": 1771.26171875, "1": 80}, "size": {"0": 386.15625, "1": 252.4296875}, "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "text", "type": "STRING", "link": 18, "widget": {"name": "text"}}], "outputs": [{"name": "STRING", "type": "STRING", "links": [15], "slot_index": 0, "shape": 6}], "properties": {"Node name for S&R": "ShowText|pysssss"}, "widgets_values": ["", "Convert the following text into a suitable prompt for text2img (stable diffusion). Do not output anything other than the prompt:The image is a portrait of a young woman posing outdoors. She has long, straight hair and is wearing a white kimono with light-colored, intricate detailing on the right side of her clothing. The woman appears to be standing in a park or garden setting, as there are trees and a fence visible behind her. Her pose suggests a relaxed and casual demeanor, with one hand gently touching the side of her face while the other is slightly extended downwards. She is looking directly at the camera with a neutral expression on her face. The photo captures natural light, which casts soft shadows on the ground and enhances the greenery in the background."]}, {"id": 23, "type": "CLIPTextEncode", "pos": {"0": 3143.53662109375, "1": 451.31304931640625}, "size": {"0": 422.84503173828125, "1": 164.31304931640625}, "flags": {}, "order": 13, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 27}, {"name": "text", "type": "STRING", "link": 36, "widget": {"name": "text"}}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [31], "slot_index": 0}], "title": "CLIP Text Encode (Positive Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["an extremely good looking asian guy"], "color": "#232", "bgcolor": "#353"}, {"id": 28, "type": "CLIPTextEncode", "pos": {"0": 3143.53662109375, "1": 80}, "size": {"0": 422.84503173828125, "1": 164.31304931640625}, "flags": {"collapsed": true}, "order": 6, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 34, "slot_index": 0}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [32], "slot_index": 0}], "title": "CLIP Text Encode (Negative Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": [""], "color": "#322", "bgcolor": "#533"}, {"id": 29, "type": "Note", "pos": {"0": 82.13821411132812, "1": 80}, "size": {"0": 282.8617858886719, "1": 164.08004760742188}, "flags": {}, "order": 1, "mode": 0, "inputs": [], "outputs": [], "properties": {"text": ""}, "widgets_values": ["Note that Flux dev and schnell do not have any negative prompt so CFG should be set to 1.0. Setting CFG to 1.0 means the negative prompt is ignored.\n\nThe schnell model is a distilled model that can generate a good image with only 4 steps."], "color": "#432", "bgcolor": "#653"}, {"id": 18, "type": "ShowText|pysssss", "pos": {"0": 2657.41796875, "1": 258}, "size": {"0": 436.1186218261719, "1": 210.53955078125}, "flags": {}, "order": 12, "mode": 0, "inputs": [{"name": "text", "type": "STRING", "link": 20, "widget": {"name": "text"}}], "outputs": [{"name": "STRING", "type": "STRING", "links": [36], "slot_index": 0, "shape": 6}], "properties": {"Node name for S&R": "ShowText|pysssss"}, "widgets_values": ["", "\"A young woman posing outdoors in a park or garden setting, wearing a white kimono with intricate detailing on the right side, long straight hair, and a relaxed, casual demeanor. She looks directly at the camera with a neutral expression, one hand gently touching her face and the other slightly extended downwards, surrounded by natural light, trees, and a fence in the background.\""]}, {"id": 22, "type": "VAEEncode", "pos": {"0": 3356.381591796875, "1": 324.31304931640625}, "size": {"0": 210, "1": 46}, "flags": {}, "order": 7, "mode": 0, "inputs": [{"name": "pixels", "type": "IMAGE", "link": 25}, {"name": "vae", "type": "VAE", "link": 35}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [41], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "VAEEncode"}}, {"id": 19, "type": "LoadImage", "pos": {"0": 50, "1": 324.0800476074219}, "size": {"0": 315, "1": 314.00006103515625}, "flags": {}, "order": 2, "mode": 0, "inputs": [], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [21, 25], "shape": 3}, {"name": "MASK", "type": "MASK", "links": null, "shape": 3}], "properties": {"Node name for S&R": "LoadImage"}, "widgets_values": ["ComfyUI_temp_qekgf_00001_.png", "image"]}, {"id": 32, "type": "UpscaleModelLoader", "pos": {"0": 3981.381591796875, "1": 80}, "size": {"0": 315, "1": 58}, "flags": {}, "order": 3, "mode": 0, "inputs": [], "outputs": [{"name": "UPSCALE_MODEL", "type": "UPSCALE_MODEL", "links": [42], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "UpscaleModelLoader"}, "widgets_values": ["RealESRGAN_x4.pth"]}, {"id": 33, "type": "SaveImage", "pos": {"0": 4736.58154296875, "1": 80}, "size": [315, 270], "flags": {}, "order": 18, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 44}], "outputs": [], "properties": {}, "widgets_values": ["ComfyUI"]}, {"id": 31, "type": "ImageUpscaleWithModel", "pos": {"0": 4346.3818359375, "1": 80}, "size": {"0": 340.20001220703125, "1": 46}, "flags": {}, "order": 16, "mode": 0, "inputs": [{"name": "upscale_model", "type": "UPSCALE_MODEL", "link": 42}, {"name": "image", "type": "IMAGE", "link": 43}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [44], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "ImageUpscaleWithModel"}}, {"id": 34, "type": "PreviewImage", "pos": {"0": 4337.21044921875, "1": 278.5429992675781}, "size": [210, 246], "flags": {}, "order": 17, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 45}], "outputs": [], "properties": {"Node name for S&R": "PreviewImage"}}, {"id": 24, "type": "VAEDecode", "pos": {"0": 4086.381591796875, "1": 218}, "size": {"0": 210, "1": 46}, "flags": {}, "order": 15, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 28}, {"name": "vae", "type": "VAE", "link": 29}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [43, 45], "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}}, {"id": 26, "type": "CheckpointLoaderSimple", "pos": {"0": 2778.53662109375, "1": 80}, "size": {"0": 315, "1": 98}, "flags": {}, "order": 4, "mode": 0, "inputs": [], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [30], "slot_index": 0, "shape": 3}, {"name": "CLIP", "type": "CLIP", "links": [27, 34], "slot_index": 1, "shape": 3}, {"name": "VAE", "type": "VAE", "links": [29, 35], "slot_index": 2, "shape": 3}], "properties": {"Node name for S&R": "CheckpointLoaderSimple"}, "widgets_values": ["flux1-dev-fp8.safetensors"]}, {"id": 27, "type": "KSampler", "pos": {"0": 3616.381591796875, "1": 80}, "size": {"0": 315, "1": 474}, "flags": {}, "order": 14, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 30}, {"name": "positive", "type": "CONDITIONING", "link": 31}, {"name": "negative", "type": "CONDITIONING", "link": 32}, {"name": "latent_image", "type": "LATENT", "link": 41}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [28], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [607111153319982, "randomize", 20, 1, "euler", "simple", 0.3]}], "links": [[14, 12, 0, 13, 0, "STRING"], [15, 17, 0, 14, 0, "STRING"], [16, 16, 0, 15, 0, "STRING"], [17, 13, 0, 15, 1, "STRING"], [18, 15, 0, 17, 0, "STRING"], [20, 14, 0, 18, 0, "STRING"], [21, 19, 0, 12, 0, "IMAGE"], [25, 19, 0, 22, 0, "IMAGE"], [27, 26, 1, 23, 0, "CLIP"], [28, 27, 0, 24, 0, "LATENT"], [29, 26, 2, 24, 1, "VAE"], [30, 26, 0, 27, 0, "MODEL"], [31, 23, 0, 27, 1, "CONDITIONING"], [32, 28, 0, 27, 2, "CONDITIONING"], [34, 26, 1, 28, 0, "CLIP"], [35, 26, 2, 22, 1, "VAE"], [36, 18, 0, 23, 1, "STRING"], [41, 22, 0, 27, 3, "LATENT"], [42, 32, 0, 31, 0, "UPSCALE_MODEL"], [43, 24, 0, 31, 1, "IMAGE"], [44, 31, 0, 33, 0, "IMAGE"], [45, 24, 0, 34, 0, "IMAGE"]], "groups": [], "config": {}, "extra": {"ds": {"scale": 1.01525597994771, "offset": [-3310.9666902845247, 106.06430981935337]}, "groupNodes": {"yuichkun::sdxl-turbo": {"author": "Yuichi Yogo", "category": "", "config": {"1": {"input": {"ckpt_name": {"visible": false}}}, "6": {"input": {"add_noise": {"visible": false}}, "output": {"1": {"visible": false}}}}, "datetime": 1725553184575, "external": [[7, 0, "IMAGE"]], "links": [[1, 0, 3, 0, 4, "MODEL"], [1, 1, 4, 0, 4, "CLIP"], [1, 1, 5, 0, 4, "CLIP"], [1, 0, 6, 0, 4, "MODEL"], [5, 0, 6, 1, 7, "CONDITIONING"], [4, 0, 6, 2, 8, "CONDITIONING"], [0, 0, 6, 3, 3, "SAMPLER"], [3, 0, 6, 4, 6, "SIGMAS"], [2, 0, 6, 5, 5, "LATENT"], [6, 0, 7, 0, 9, "LATENT"], [1, 2, 7, 1, 4, "VAE"]], "nodes": [{"flags": {}, "id": -1, "index": 0, "inputs": [], "mode": 0, "order": 0, "outputs": [{"links": [], "name": "SAMPLER", "shape": 3, "type": "SAMPLER"}], "pos": {"0": 1031, "1": 413, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "KSamplerSelect"}, "size": {"0": 315, "1": 58}, "type": "KSamplerSelect", "widgets_values": ["euler"]}, {"flags": {}, "id": -1, "index": 1, "inputs": [], "mode": 0, "order": 1, "outputs": [{"links": [], "name": "MODEL", "shape": 3, "slot_index": 0, "type": "MODEL"}, {"links": [], "name": "CLIP", "shape": 3, "slot_index": 1, "type": "CLIP"}, {"links": [], "name": "VAE", "shape": 3, "slot_index": 2, "type": "VAE"}], "pos": {"0": 538, "1": 262, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "CheckpointLoaderSimple"}, "size": {"0": 343.69647216796875, "1": 98}, "type": "CheckpointLoaderSimple", "widgets_values": ["SDXL-TURBO/sd_xl_turbo_1.0_fp16.safetensors"]}, {"flags": {}, "id": -1, "index": 2, "inputs": [], "mode": 0, "order": 2, "outputs": [{"links": [], "name": "LATENT", "slot_index": 0, "type": "LATENT"}], "pos": {"0": 992, "1": 916, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "EmptyLatentImage"}, "size": {"0": 315, "1": 106}, "type": "EmptyLatentImage", "widgets_values": [512, 512, 1]}, {"flags": {}, "id": -1, "index": 3, "inputs": [{"link": null, "name": "model", "slot_index": 0, "type": "MODEL"}], "mode": 0, "order": 3, "outputs": [{"links": [], "name": "SIGMAS", "shape": 3, "slot_index": 0, "type": "SIGMAS"}], "pos": {"0": 1151, "1": 106, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "SDTurboScheduler"}, "size": {"0": 315, "1": 82}, "type": "SDTurboScheduler", "widgets_values": [1, 1]}, {"flags": {}, "id": -1, "index": 4, "inputs": [{"link": null, "name": "clip", "type": "CLIP"}], "mode": 0, "order": 4, "outputs": [{"links": [], "name": "CONDITIONING", "slot_index": 0, "type": "CONDITIONING"}], "pos": {"0": 526, "1": 584, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "CLIPTextEncode"}, "size": {"0": 425.27801513671875, "1": 180.6060791015625}, "title": "Negative Prompt", "type": "CLIPTextEncode", "widgets_values": [""]}, {"flags": {}, "id": -1, "index": 5, "inputs": [{"link": null, "name": "clip", "slot_index": 0, "type": "CLIP"}, {"link": null, "name": "text", "type": "STRING", "widget": {"name": "text"}}], "mode": 0, "order": 5, "outputs": [{"links": [], "name": "CONDITIONING", "slot_index": 0, "type": "CONDITIONING"}], "pos": {"0": 397, "1": 529, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "CLIPTextEncode"}, "size": {"0": 422.84503173828125, "1": 164.31304931640625}, "title": "Positive Prompt", "type": "CLIPTextEncode", "widgets_values": [""]}, {"flags": {}, "id": -1, "index": 6, "inputs": [{"link": null, "name": "model", "slot_index": 0, "type": "MODEL"}, {"link": null, "name": "positive", "slot_index": 1, "type": "CONDITIONING"}, {"link": null, "name": "negative", "type": "CONDITIONING"}, {"link": null, "name": "sampler", "slot_index": 3, "type": "SAMPLER"}, {"link": null, "name": "sigmas", "slot_index": 4, "type": "SIGMAS"}, {"link": null, "name": "latent_image", "slot_index": 5, "type": "LATENT"}], "mode": 0, "order": 6, "outputs": [{"links": [], "name": "output", "shape": 3, "slot_index": 0, "type": "LATENT"}, {"links": null, "name": "denoised_output", "shape": 3, "type": "LATENT"}], "pos": {"0": 1379, "1": 491, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "SamplerCustom"}, "size": {"0": 355.20001220703125, "1": 230}, "type": "SamplerCustom", "widgets_values": [true, 0, "randomize", 8]}, {"flags": {}, "id": -1, "index": 7, "inputs": [{"link": null, "name": "samples", "type": "LATENT"}, {"link": null, "name": "vae", "slot_index": 1, "type": "VAE"}], "mode": 0, "order": 7, "outputs": [{"links": [], "name": "IMAGE", "slot_index": 0, "type": "IMAGE"}], "pos": {"0": 1599, "1": 354, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "VAEDecode"}, "size": {"0": 210, "1": 46}, "type": "VAEDecode"}], "packname": "", "version": "0.0"}, "yuichkun::stable-audio": {"author": "Yuichi Yogo", "category": "audio", "config": {"0": {"input": {"ckpt_name": {"visible": false}}}, "1": {"input": {"clip_name": {"visible": false}, "type": {"visible": false}}}, "4": {"input": {"text": {"name": "Negative Prompt"}}}}, "datetime": 1725554376722, "external": [[6, 0, "AUDIO"]], "links": [[1, 0, 3, 0, 10, "CLIP"], [1, 0, 4, 0, 10, "CLIP"], [0, 0, 5, 0, 4, "MODEL"], [3, 0, 5, 1, 6, "CONDITIONING"], [4, 0, 5, 2, 7, "CONDITIONING"], [2, 0, 5, 3, 11, "LATENT"], [5, 0, 6, 0, 3, "LATENT"], [0, 2, 6, 1, 4, "VAE"]], "nodes": [{"flags": {}, "id": -1, "index": 0, "inputs": [], "mode": 0, "order": 0, "outputs": [{"links": [], "name": "MODEL", "slot_index": 0, "type": "MODEL"}, {"links": [], "name": "CLIP", "slot_index": 1, "type": "CLIP"}, {"links": [], "name": "VAE", "slot_index": 2, "type": "VAE"}], "pos": {"0": 713, "1": 234, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "CheckpointLoaderSimple"}, "size": {"0": 336, "1": 98}, "type": "CheckpointLoaderSimple", "widgets_values": ["stable_audio_open_1.0.safetensors"]}, {"flags": {}, "id": -1, "index": 1, "inputs": [], "mode": 0, "order": 1, "outputs": [{"links": [], "name": "CLIP", "shape": 3, "slot_index": 0, "type": "CLIP"}], "pos": {"0": 713, "1": 90, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "CLIPLoader"}, "size": {"0": 335.6534118652344, "1": 82}, "type": "CLIPLoader", "widgets_values": ["t5_base.safetensors", "stable_audio"]}, {"flags": {}, "id": -1, "index": 2, "inputs": [], "mode": 0, "order": 2, "outputs": [{"links": [], "name": "LATENT", "shape": 3, "type": "LATENT"}], "pos": {"0": 1289, "1": 474, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "EmptyLatentAudio"}, "size": {"0": 240, "1": 58}, "type": "EmptyLatentAudio", "widgets_values": [47.6]}, {"bgcolor": "#353", "color": "#232", "flags": {}, "id": -1, "index": 3, "inputs": [{"link": null, "name": "clip", "type": "CLIP"}, {"link": null, "name": "text", "type": "STRING", "widget": {"name": "text"}}], "mode": 0, "order": 3, "outputs": [{"links": [], "name": "CONDITIONING", "slot_index": 0, "type": "CONDITIONING"}], "pos": {"0": 1097, "1": 90, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "CLIPTextEncode"}, "size": {"0": 432, "1": 144}, "type": "CLIPTextEncode", "widgets_values": ["heaven church electronic dance music"]}, {"bgcolor": "#533", "color": "#322", "flags": {}, "id": -1, "index": 4, "inputs": [{"link": null, "name": "clip", "type": "CLIP"}], "mode": 0, "order": 4, "outputs": [{"links": [], "name": "CONDITIONING", "slot_index": 0, "type": "CONDITIONING"}], "pos": {"0": 1097, "1": 282, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "CLIPTextEncode"}, "size": {"0": 432, "1": 144}, "type": "CLIPTextEncode", "widgets_values": [""]}, {"flags": {}, "id": -1, "index": 5, "inputs": [{"link": null, "name": "model", "type": "MODEL"}, {"link": null, "name": "positive", "type": "CONDITIONING"}, {"link": null, "name": "negative", "type": "CONDITIONING"}, {"link": null, "name": "latent_image", "slot_index": 3, "type": "LATENT"}], "mode": 0, "order": 5, "outputs": [{"links": [], "name": "LATENT", "slot_index": 0, "type": "LATENT"}], "pos": {"0": 1577, "1": 90, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "KSampler"}, "size": {"0": 315, "1": 262}, "type": "KSampler", "widgets_values": [1103134701216948, "randomize", 50, 4.98, "dpmpp_3m_sde_gpu", "exponential", 1]}, {"flags": {}, "id": -1, "index": 6, "inputs": [{"link": null, "name": "samples", "type": "LATENT"}, {"link": null, "name": "vae", "slot_index": 1, "type": "VAE"}], "mode": 0, "order": 6, "outputs": [{"links": [], "name": "AUDIO", "shape": 3, "slot_index": 0, "type": "AUDIO"}], "pos": {"0": 1913, "1": 90, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "properties": {"Node name for S&R": "VAEDecodeAudio"}, "size": {"0": 210, "1": 46}, "type": "VAEDecodeAudio"}], "packname": "", "version": "0.0"}}}, "version": 0.4}